{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from win10toast import ToastNotifier\n",
    "toast = ToastNotifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from models.train import train, test\n",
    "from models.models import StateActionModel\n",
    "from models.utils import set_seed\n",
    "\n",
    "from game.simulator import load_simulator_yarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(ld, indent=0):\n",
    "    with open('result.txt', 'w', encoding='utf-8') as file:\n",
    "        for d in tqdm(ld):\n",
    "            file.write('{' + '\\n')\n",
    "            for key, value in d.items():\n",
    "                file.write('\\t' * (indent+1) + str(key) + ':' + str(value) + '\\n')\n",
    "                # file.write('\\t' * (indent+1) + str(key) + '\\n')\n",
    "                # file.write('\\t' * (indent+2) + str(value) + '\\n')\n",
    "            file.write('},\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = True\n",
    "\n",
    "seed = 4444\n",
    "\n",
    "metric_filter_1 = 'test_mcc'\n",
    "metric_filter_2 = 'val_mcc'\n",
    "\n",
    "data_dir = '../yarnScripts'\n",
    "log_path = './logs'\n",
    "save_path = './saved'\n",
    "\n",
    "graph = load_simulator_yarn('../yarnScripts').graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_bert'\n",
    "log_dir = f'{log_path}_bert'\n",
    "\n",
    "dict_model = dict(\n",
    "    shared_out_dim=[125,75,200],\n",
    "    state_layers=[[20], [30]],\n",
    "    action_layers=[[20], [30]],\n",
    "    out_features=[1],\n",
    "    lstm_model=[False],\n",
    "    bert_name=[\"bert-base-multilingual-cased\"],\n",
    "    # training parameters\n",
    ")\n",
    "\n",
    "list_model = [dict(zip(dict_model.keys(), k)) for k in itertools.product(*dict_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        set_seed(seed)\n",
    "        d = d.copy()\n",
    "\n",
    "        train(\n",
    "            model=StateActionModel(**d),\n",
    "            dict_model=d,\n",
    "            log_dir=log_dir,\n",
    "            graph=graph,\n",
    "            save_path=save_model,\n",
    "            lr=1e-3,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=80,\n",
    "            batch_size=8,\n",
    "            num_workers=0,\n",
    "            scheduler_mode='max_val_acc',\n",
    "            debug_mode=False,\n",
    "            steps_save=20,\n",
    "            use_cpu=False,\n",
    "            freeze_bert=True,\n",
    "            balanced_actions=False,\n",
    "            scheduler_patience=20,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [4:09:54<00:00, 68.78s/it]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = test(\n",
    "    graph=graph,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "toast.show_toast(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dict': {'shared_out_dim': 125,\n",
       "  'state_layers': [20],\n",
       "  'action_layers': [20],\n",
       "  'out_features': 1,\n",
       "  'lstm_model': False,\n",
       "  'bert_name': 'bert-base-multilingual-cased',\n",
       "  'train_lr': 0.001,\n",
       "  'train_optimizer_name': 'adamw',\n",
       "  'train_batch_size': 8,\n",
       "  'train_scheduler_mode': 'max_val_mcc',\n",
       "  'train_balanced_actions': False,\n",
       "  'train_augment_negative': False,\n",
       "  'epoch': 10,\n",
       "  'train_loss': 0.58715725,\n",
       "  'train_acc': 0.8504436016082764,\n",
       "  'val_acc': 0.8471336960792542,\n",
       "  'val_mcc': 0.7060012894938652,\n",
       "  'train_mcc': 0.7019989926701873,\n",
       "  'test_mcc': 0.6549151177748015,\n",
       "  'test_acc': 0.8301886320114136,\n",
       "  'path_name': 'c:\\\\Users\\\\vibal\\\\PycharmProjects\\\\text-games\\\\notebooks\\\\saved_bert\\\\125_[20]_[20]_1_False_bert-base-multilingual-cased_0.001_adamw_8_max_val_mcc_False_False_10'},\n",
       " 'train_cm': [array([[404.,  29.],\n",
       "         [ 89., 267.]], dtype=float32)],\n",
       " 'val_cm': [array([[78.,  4.],\n",
       "         [20., 55.]], dtype=float32)],\n",
       " 'test_cm': [array([[52.,  7.],\n",
       "         [11., 36.]], dtype=float32)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shared_out_dim': 125,\n",
       " 'state_layers': [30],\n",
       " 'action_layers': [20],\n",
       " 'out_features': 1,\n",
       " 'lstm_model': False,\n",
       " 'bert_name': 'bert-base-multilingual-cased',\n",
       " 'train_lr': 0.001,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 8,\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_balanced_actions': False,\n",
       " 'train_augment_negative': False,\n",
       " 'epoch': 100,\n",
       " 'train_loss': 0.28085804,\n",
       " 'train_acc': 1.0,\n",
       " 'val_acc': 0.9999998807907104,\n",
       " 'val_mcc': 1.0,\n",
       " 'train_mcc': 1.0,\n",
       " 'test_mcc': 1.0,\n",
       " 'test_acc': 0.9999999403953552,\n",
       " 'path_name': 'c:\\\\Users\\\\vibal\\\\PycharmProjects\\\\text-games\\\\notebooks\\\\saved_bert\\\\125_[30]_[20]_1_False_bert-base-multilingual-cased_0.001_adamw_8_max_val_mcc_False_False_100'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shared_out_dim': 125,\n",
       " 'state_layers': [30],\n",
       " 'action_layers': [20],\n",
       " 'out_features': 1,\n",
       " 'lstm_model': False,\n",
       " 'bert_name': 'bert-base-multilingual-cased',\n",
       " 'train_lr': 0.001,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 8,\n",
       " 'train_scheduler_mode': 'max_val_mcc',\n",
       " 'train_balanced_actions': False,\n",
       " 'train_augment_negative': False,\n",
       " 'epoch': 100,\n",
       " 'train_loss': 0.28085804,\n",
       " 'train_acc': 1.0,\n",
       " 'val_acc': 0.9999998807907104,\n",
       " 'val_mcc': 1.0,\n",
       " 'train_mcc': 1.0,\n",
       " 'test_mcc': 1.0,\n",
       " 'test_acc': 0.9999999403953552,\n",
       " 'path_name': 'c:\\\\Users\\\\vibal\\\\PycharmProjects\\\\text-games\\\\notebooks\\\\saved_bert\\\\125_[30]_[20]_1_False_bert-base-multilingual-cased_0.001_adamw_8_max_val_mcc_False_False_100'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = all[sort_idx[0]]['test_cm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'c:\\\\Users\\\\vibal\\\\PycharmProjects\\\\text-games\\\\venv\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.class_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Fine-tuned augment negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_neg_nf'\n",
    "log_dir = f'{log_path}_neg_nf'\n",
    "\n",
    "dict_model = dict(\n",
    "    shared_out_dim=[128,64,256],\n",
    "    state_layers=[[20], [30]],\n",
    "    action_layers=[[20], [30]],\n",
    "    # shared_out_dim=[75],\n",
    "    # state_layers=[[30]],\n",
    "    # action_layers=[[30]],\n",
    "    out_features=[1],\n",
    "    lstm_model=[False],\n",
    "    bert_name=[\"bert-base-multilingual-cased\"],\n",
    "    # training parameters\n",
    ")\n",
    "\n",
    "list_model = [dict(zip(dict_model.keys(), k)) for k in itertools.product(*dict_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        set_seed(seed)\n",
    "        d = d.copy()\n",
    "\n",
    "        train(\n",
    "            model=StateActionModel(**d),\n",
    "            dict_model=d,\n",
    "            log_dir=log_dir,\n",
    "            graph=graph,\n",
    "            save_path=save_model,\n",
    "            lr=1e-3,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=120,\n",
    "            batch_size=16,\n",
    "            num_workers=0,\n",
    "            scheduler_mode='max_val_mcc',\n",
    "            debug_mode=False,\n",
    "            steps_save=25,\n",
    "            use_cpu=False,\n",
    "            freeze_bert=True,\n",
    "            balanced_actions=False,\n",
    "            augment_negative=True,\n",
    "            scheduler_patience=15,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [44:03<00:00, 50.83s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = test(\n",
    "    graph=graph,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "toast.show_toast(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dict': {'shared_out_dim': 125,\n",
       "  'state_layers': [20],\n",
       "  'action_layers': [20],\n",
       "  'out_features': 1,\n",
       "  'lstm_model': False,\n",
       "  'bert_name': 'bert-base-multilingual-cased',\n",
       "  'train_lr': 0.001,\n",
       "  'train_optimizer_name': 'adamw',\n",
       "  'train_batch_size': 16,\n",
       "  'train_scheduler_mode': 'max_val_acc',\n",
       "  'train_balanced_actions': False,\n",
       "  'train_augment_negative': True,\n",
       "  'train_scheduler_patience': 15,\n",
       "  'epoch': 100,\n",
       "  'train_loss': 0.55674917,\n",
       "  'train_acc': 0.7579213976860046,\n",
       "  'val_acc': 0.7834393978118896,\n",
       "  'val_mcc': 0.5819756820944954,\n",
       "  'path_name': 'saved_neg\\\\125_[20]_[20]_1_False_bert-base-multilingual-cased_0.001_adamw_16_max_val_acc_False_True_15_100',\n",
       "  'train_mcc': 0.5488043981095888,\n",
       "  'test_mcc': 0.6164802220221751,\n",
       "  'test_acc': 0.7830188274383545},\n",
       " 'train_cm': [array([[279., 154.],\n",
       "         [ 37., 319.]], dtype=float32)],\n",
       " 'val_cm': [array([[57., 25.],\n",
       "         [ 9., 66.]], dtype=float32)],\n",
       " 'test_cm': [array([[38., 21.],\n",
       "         [ 2., 45.]], dtype=float32)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shared_out_dim': 125,\n",
       " 'state_layers': [20],\n",
       " 'action_layers': [20],\n",
       " 'out_features': 1,\n",
       " 'lstm_model': False,\n",
       " 'bert_name': 'bert-base-multilingual-cased',\n",
       " 'train_lr': 0.001,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 16,\n",
       " 'train_scheduler_mode': 'max_val_acc',\n",
       " 'train_balanced_actions': False,\n",
       " 'train_augment_negative': True,\n",
       " 'train_scheduler_patience': 15,\n",
       " 'epoch': 50,\n",
       " 'train_loss': 0.59630173,\n",
       " 'train_acc': 0.8821292519569397,\n",
       " 'val_acc': 0.9044585227966309,\n",
       " 'val_mcc': 0.8088043734960404,\n",
       " 'path_name': 'saved_neg\\\\125_[20]_[20]_1_False_bert-base-multilingual-cased_0.001_adamw_16_max_val_acc_False_True_15_50',\n",
       " 'train_mcc': 0.7640110776323683,\n",
       " 'test_mcc': 0.7834478150981965,\n",
       " 'test_acc': 0.8867923617362976}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shared_out_dim': 125,\n",
       " 'state_layers': [20],\n",
       " 'action_layers': [20],\n",
       " 'out_features': 1,\n",
       " 'lstm_model': False,\n",
       " 'bert_name': 'bert-base-multilingual-cased',\n",
       " 'train_lr': 0.001,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 16,\n",
       " 'train_scheduler_mode': 'max_val_acc',\n",
       " 'train_balanced_actions': False,\n",
       " 'train_augment_negative': True,\n",
       " 'train_scheduler_patience': 15,\n",
       " 'epoch': 50,\n",
       " 'train_loss': 0.59630173,\n",
       " 'train_acc': 0.8821292519569397,\n",
       " 'val_acc': 0.9044585227966309,\n",
       " 'val_mcc': 0.8088043734960404,\n",
       " 'path_name': 'saved_neg\\\\125_[20]_[20]_1_False_bert-base-multilingual-cased_0.001_adamw_16_max_val_acc_False_True_15_50',\n",
       " 'train_mcc': 0.7640110776323683,\n",
       " 'test_mcc': 0.7834478150981965,\n",
       " 'test_acc': 0.8867923617362976}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = all[sort_idx[0]]['test_cm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'c:\\\\Users\\\\vibal\\\\PycharmProjects\\\\text-games\\\\venv\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyMAAAJUCAYAAAAGg/kIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAh9klEQVR4nO3deZilZXkn4N8DjUGQrUUUAUWiE4c4kRhXHI1iXDCZKAkKmoUxJK3GxC3GLTGIY664Ro1otEVHjIhCNCIxiogSRA2IgIiNW9yjiLKogCPQ9c4fdRqKlu6qbr5T31tV931d5+pzvnPOd54usbqe+n3P+1ZrLQAAAIttm7ELAAAAVibNCAAAMArNCAAAMArNCAAAMArNCAAAMArNCAAAMIpVYxewKdf98GvWHAbYQo844MljlwCwpHz8O6fV2DUsxGL+bLzd7vst2tdEMgIAAIyi22QEAACYmFk/dgVTIRkBAABGIRkBAIDetZmxK5gKyQgAADAKyQgAAPRuRjICAAAwGMkIAAB0rpkZAQAAGI5kBAAAemdmBAAAYDiaEQAAYBQu0wIAgN4ZYAcAABiOZAQAAHo3s37sCqZCMgIAAIxCMgIAAL0zMwIAADAcyQgAAPTOpocAAADDkYwAAEDnmpkRAACA4UhGAACgd2ZGAAAAhiMZAQCA3pkZAQAAGI5kBAAAejezfuwKpkIyAgAAjEIzAgAAjMJlWgAA0DsD7AAAAMORjAAAQO9seggAADAcyQgAAPTOzAgAAMBwJCMAANA7MyMAAADDkYwAAEDnWls/dglTIRkBAABGIRkBAIDeWU0LAABgOJIRAADondW0AAAAhiMZAQCA3pkZAQAAGI5mBAAAGIXLtAAAoHczNj0EAAAYjGQEAAB6Z4AdAABgOJIRAADonU0PAQAAhiMZAQCA3pkZAQAAGI5kBAAAemdmBAAAYDiSEQAA6J1kBAAAYDiSEQAA6Fxr68cuYSokIwAAwCgkIwAA0DszIwAAAMPRjAAAAKNwmRYAAPSuuUwLAABgMJIRAADonQF2AACA4UhGAACgd2ZGAAAAhiMZAQCA3pkZAQAAGI5kBAAAemdmBAAAYDiSEQAA6J2ZEQAAgOFIRgAAoHeSEQAAgOFIRgAAoHdW0wIAABiOZgQAABiFy7QAAKB3BtgBAACGIxkBAIDeGWAHAAAYjmQEAAB6Z2YEAABgOJIRAADonZkRAACA4UhGAACgd2ZGAAAAhiMZAQCA3klGAAAAhiMZAQCA3rU2dgVTIRkBAABGIRkBAIDemRkBAAAYjmYEAAAYhcu0AACgdy7TAgAAGI5mBAAAetdmFu+2QFW1bVWdX1X/Onl8l6o6u6q+WlXvqapbzXcOzQgAALA1npHk4jmPX57kNa21uya5IsmR851AMwIAAL2bmVm82wJU1d5JfjPJsZPHleSgJP88eclxSR4733k0IwAAwJZ6bZLnJtnQvdw2yZWttesnj7+TZK/5TqIZAQCA3rW2aLeqWlNV5865rZlbSlX9VpJLW2ufvaV/LUv7AgAAN2itrU2ydjMveWCS366qRyfZPsnOSV6XZNeqWjVJR/ZO8l/zfZZkBAAAetfRzEhr7QWttb1ba/smOTzJx1prv5fk40kOnbzsiCQnz3cuzQgAADCE5yV5dlV9NbMzJG+d7w0u0wIAgN51ugN7a+2MJGdM7n8tyX235P2SEQAAYBSSEQAA6N0W7Iy+lEhGAACAUUhGAACgc22mjV3CVEhGAACAUWhGAACAUbhMCwAAetfp0r63lGQEAAAYhWQEAAB6Z2lfAACA4UhGAACgd5b2BQAAGI5kBAAAemc1LQAAgOFIRgAAoHeSEQAAgOFIRgAAoHfNaloAAACDkYwAAEDvzIwAAAAMZ6rNSFXtX1WnV9U1VfXdqnpJVW07zc8EAIBlZ6Yt3m0RTe0yraraLclHk6xL8pgkv5jk1ZltgP56Wp8LAAAsDdOcGXlKklsn+Z3W2o+TnFZVOyd5cVW9YnIMurd+/focduTTs8ftds8bX3l0zv7sBXnVMcfmuuuuz/6/dNe85AXPyqpVAj+ADZ77qr/I/X/jfrnyh1fmj35jTZJkp113yt+88a9yh33ukEu+fUmOfupLc9WPrhq5UmBs07xM6+Akp27UdLw7sw3Kr0/xc2FQ7zzp5Oy3752SJDMzM3nhS1+dVx79/Lz/nW/KHe+wR07+0EdHrhCgLx8+6SN53u+/8CbHnvi0w3LeJ8/PHzzof+e8T56fJz7t8JGqgyWqzSzebRFNsxm5e5Ivzj3QWvtWkmsmz0H3Lrn0BznzU+fkd//XI5MkV/7ox9lu1arse6e9kyQPuM+98tEzzhqzRIDuXHj25/PjK39yk2MHPuLAnHrSaUmSU086LQ985IFjlAZ0ZprNyG5JrryZ41dMnoPuvfx1b86z//TIVM3+X2W3XXfJ+vUzuejiLydJPnLGWbnk0h+OWSLAkrB6991y+aWXJ0kuv/TyrN7djwKwRQyww8pyxifPzurdds0v3/1uOee8C5MkVZVXvuT5ecU/rM21112XA+97r2yzjRWyAbZUW6a7SQNbZprNyBVJdrmZ47tNnvs5VbUmyZokeeOrX5o//sMnTK86mMf5F67LGWf9Rz7x6c/kZ9del6uvvibPO/oVeflRz807/vFVSZJPnv3ZfPPb/zVypQD9u/yHV2T1HqtnU5E9VueKy64cuyRYUtoy3fRwms3IF7PRbEhV7ZNkh2w0S7JBa21tkrVJct0Pv+ZXJozqWU99Up711CclSc4578K8/YT35uVHPTeXXXFlbrvbrrn22mvztuNPypojDGECzOdTp306j3zcw3PCG96TRz7u4fnURz41dklAB6bZjHwoyV9W1U6ttQ1TbIcl+WmSf5/i58JU/d/j/zn//qlz0mZmctghv5n7/doBY5cE0JW/PuaFOeABv5JdVu+SEz/zrrz91e/ICce8O0e96UV59OEH5/vf+X6OfupLxy4TlpZFnuVYLDWtazYnmx6uS3JRkpcn2S/J3yd5bWtt3k0PJSMAW+4RBzx57BIAlpSPf+e0GruGhbj6b/9w0X423vGv3rFoX5OpJSOttSuq6mFJjklySmZX1npNkhdP6zMBAGBZWuT9PxbLVFfTaq2tS3LQND8DAABYmiztCwAAvVumMyM2SAAAAEYhGQEAgN4t031GJCMAAMAoJCMAANA7MyMAAADD0YwAAACjcJkWAAD0bplueigZAQAARiEZAQCA3hlgBwAAGI5kBAAAOtdseggAADAcyQgAAPTOzAgAAMBwJCMAANA7yQgAAMBwJCMAANA7O7ADAAAMRzICAAC9MzMCAAAwHMkIAAB0rklGAAAAhqMZAQAARuEyLQAA6J3LtAAAAIYjGQEAgN7N2PQQAABgMJIRAADonZkRAACA4UhGAACgd5IRAACA4UhGAACgc61JRgAAAAYjGQEAgN6ZGQEAABiOZAQAAHonGQEAABiOZAQAADrXJCMAAADDkYwAAEDvJCMAAADD0YwAAACjcJkWAAD0bmbsAqZDMgIAAIxCMgIAAJ2ztC8AAMCAJCMAANA7yQgAAMBwJCMAANA7q2kBAAAMRzICAACds5oWAADAgCQjAADQOzMjAAAAw5GMAABA58yMAAAADEgyAgAAvTMzAgAAMBzNCAAAMAqXaQEAQOeay7QAAACGIxkBAIDeSUYAAACGIxkBAIDOmRkBAAAYkGQEAAB6JxkBAAAYjmQEAAA6Z2YEAABgQJIRAADonGQEAABgQJIRAADonGQEAABgQJoRAADoXavFu82jqravqnOq6nNV9YWqOnpy/C5VdXZVfbWq3lNVt5rvXJoRAABgS/wsyUGttXsmOSDJo6rq/klenuQ1rbW7JrkiyZHznUgzAgAALFibddXk4XaTW0tyUJJ/nhw/Lslj5zuXAXYAAOhcbwPsVbVtks8muWuSNyT5zyRXttaun7zkO0n2mu88khEAAOAGVbWmqs6dc1uz8Wtaa+tbawck2TvJfZPcfWs+SzICAACdazPzD5YP9lmtrU2ydoGvvbKqPp7kAUl2rapVk3Rk7yT/Nd/7JSMAAMCCVdXtqmrXyf1bJ3l4kouTfDzJoZOXHZHk5PnOJRkBAIDOdTYzsmeS4yZzI9skObG19q9VtS7Ju6vqpUnOT/LW+U6kGQEAABastXZhkl+9meNfy+z8yIJpRgAAoHNtAZsRLkVmRgAAgFFIRgAAoHOdzYwMRjICAACMQjICAACdW8x9RhaTZAQAABiFZAQAADrX2tgVTIdkBAAAGIVkBAAAOmdmBAAAYECaEQAAYBQu0wIAgM65TAsAAGBAkhEAAOicpX0BAAAGJBkBAIDOmRkBAAAYkGQEAAA615pkBAAAYDCSEQAA6FybGbuC6ZCMAAAAo5CMAABA52bMjAAAAAxHMgIAAJ1brqtpbbIZqarXJ9nkxvOttadPpSIAAGBF2Fwycu6iVQEAAGzSct2BfZPNSGvtuLmPq2qH1to10y8JAABYCeYdYK+qB1TVuiRfnDy+Z1W9ceqVAQAAy9pCVtN6bZJHJrksSVprn0vy4CnWBAAAzNHa4t0W04KW9m2tfXujQ+unUAsAALCCLGRp329X1YFJWlVtl+QZSS6eblkAAMAGy3WAfSHJyFOSPC3JXkm+m+SAyWMAAICtNm8y0lr7YZLfW4RaAACAmzGzTDc9XMhqWvtV1SlV9YOqurSqTq6q/RajOAAAYPlayGVa70pyYpI9k9wxyUlJTphmUQAAwI1aq0W7LaaFNCM7tNb+qbV2/eT2ziTbT7swAABgedvkzEhVrZ7c/VBVPT/Ju5O0JIcl+bdFqA0AAMji7/+xWDY3wP7ZzDYfG7KaJ895riV5wbSKAgAAlr9NNiOttbssZiEAAMDNW66raS1k08NU1T2S7J85syKttXdMqygAAGD5m7cZqaqjkjwks83IvyU5OMlZSTQjAACwCBZ7lavFspDVtA5N8rAkl7TWnpTknkl2mWpVAADAsreQy7R+2lqbqarrq2rnJJcm2WfKdQEAABMrcTWtDc6tql2TvCWzK2xdleTT0ywKAABY/uZtRlprfzq5+6aq+nCSnVtrF063LAAAYLnb3KaH99rcc62186ZTEgAAMNdKXNr31Zt5riU5aOBaAACAFWRzmx4+dDEL2dit7/igMT8eYEm66tNvGLsEAKZgJS/tCwAAMLgF7cAOAACMZ7nOjEhGAACAUczbjNSs36+qv5k8vlNV3Xf6pQEAAMns6lGLdVtMC0lG3pjkAUmeMHn8kyQmJAEAgFtkITMj92ut3auqzk+S1toVVXWrKdcFAABMrOSZkeuqattMUpuqul2SmalWBQAALHsLSUb+Icm/JNmjqv42yaFJ/nqqVQEAADdYrvuMzNuMtNaOr6rPJnlYkkry2NbaxVOvDAAAWNbmbUaq6k5JrklyytxjrbVvTbMwAABg1nKdkVjIZVofzOy8SCXZPsldknwpyS9PsS4AAGCZW8hlWv9j7uOquleSP51aRQAAwE20LM+ZkS3egb21dl6S+02hFgAAYAVZyMzIs+c83CbJvZJ8d2oVAQAAK8JCZkZ2mnP/+szOkLx3OuUAAAAbm2ljVzAdm21GJpsd7tRae84i1QMAAKwQm2xGqmpVa+36qnrgYhYEAADc1MwyHWDfXDJyTmbnQy6oqg8kOSnJ1RuebK29b8q1AQAAy9hCZka2T3JZkoNy434jLYlmBAAAFsFyXdp3c83IHpOVtC7KjU3IBst0hAYAAFgsm2tGtk1ym+Rm2zDNCAAALJKZsQuYks01I99rrb1k0SoBAABWlM01I8vzwjQAAFhiluvMyDabee5hi1YFAACw4mwyGWmtXb6YhQAAADdvuc6MbC4ZAQAAmJqF7DMCAACMSDICAAAwIMkIAAB0biWupgUAADA1mhEAAGAULtMCAIDOzSzPq7QkIwAAwDgkIwAA0LkZA+wAAADDkYwAAEDn2tgFTIlkBAAAGIVkBAAAOjczdgFTIhkBAABGIRkBAIDOzZTVtAAAAAYjGQEAgM5ZTQsAAGBAkhEAAOic1bQAAAAGJBkBAIDOzSzPxbQkIwAAwDg0IwAAwChcpgUAAJ2byfK8TksyAgAAjEIyAgAAnbPpIQAAwIAkIwAA0DlL+wIAAAxIMgIAAJ2bGbuAKZGMAAAAo5CMAABA56ymBQAAMCDJCAAAdM5qWgAAwIpXVftU1ceral1VfaGqnjE5vrqqTquqr0z+3G2+c2lGAACgczOLeFuA65P8RWtt/yT3T/K0qto/yfOTnN5au1uS0yePN0szAgAALFhr7XuttfMm93+S5OIkeyV5TJLjJi87Lslj5zuXmREAAOjcYu4zUlVrkqyZc2hta23tJl67b5JfTXJ2ktu31r43eeqSJLef77M0IwAAwA0mjcfNNh9zVdVtkrw3yTNbaz+uunHKvrXWqmreFYldpgUAAGyRqtous43I8a21900Of7+q9pw8v2eSS+c7j2YEAAA612rxbvOp2QjkrUkubq39/ZynPpDkiMn9I5KcPN+5XKYFAABsiQcm+YMkn6+qCybHXpjkZUlOrKojk3wzyePnO5FmBAAAOreYA+zzaa2dlWRTGcrDtuRcLtMCAABGIRkBAIDO9ZSMDEkyAgAAjEIyAgAAnZt3w44lSjICAACMQjICAACdm1nA/h9LkWQEAAAYhWQEAAA6ZzUtAACAAUlGAACgc5IRAACAAUlGAACgc/YZAQAAGJBkBAAAOmefEQAAgAFpRgAAgFG4TAsAADpnaV8AAIABSUYAAKBzlvYFAAAYkGQEAAA6N7NMsxHJCAAAMArJCAAAdM5qWgAAAAOSjAAAQOeW58SIZAQAABiJZAQAADpnZgQAAGBAkhEAAOjcTI1dwXRIRgAAgFFIRgAAoHN2YAcAABiQZgQAABiFy7QAAKBzy/MiLckIAAAwEskIAAB0zqaHAAAAA5KMAABA5yztCwAAMCDJCAAAdG555iKSEQAAYCSSEQAA6JzVtAAAAAYkGQEAgM5ZTQsAAGBAkhEAAOjc8sxFJCMAAMBIJCMAANA5q2kBAAAMSDMCAACMwmVaAADQubZMR9glIwAAwCgkIwAA0DkD7AAAAAOSjAAAQOdmzIwAAAAMRzICAACdW565iGQEAAAYiWQEAAA6Z2ZkK1TVXavqzVV1YVWtr6ozpvl5AADA0jHtZOSXkzw6yX8k2W7KnwUAAMuSfUa2zimttX1aa49L8oUpfxYAALCETDUZaa0t1yaOFWjvve+Yt7/tddnj9runtZZjjz0+rz/mrWOXBdCl9TMzecJfvT57rN45x/zlk/KiN52Ycy/+WnbaYfskyUue/Pjcfd87jlwlLB1tmc6MGGCHBbr++uvzl889OudfcFFuc5sdc87ZH85HTz8zF1/8lbFLA+jO8R86K/vttUeu+un/u+HYs5/46Dz8fr8yYlVAbyztCwt0ySWX5vwLLkqSXHXV1fniF7+Sve54h5GrAujP9y+7Mp+44Is55KH3GbsUWDZmFvG2mDQjsBXufOe9c8A975Gzzzl/7FIAuvOKfzolz3rCo7NN1U2Ov/7EU3Po816TV/7TKbn2uutHqg7oiWYEttCOO+6QE9/zljz7OUflJz+5auxyALry7+ddnNU73yb777f3TY4//bBH5eRXPSfveumf50dXXZO3nXLGKPUBfelqZqSq1iRZkyS17S7ZZpsdR64IbmrVqlU56T1vyQkn/Eve//4PjV0OQHcu+PI3csZ563LWBV/Kz667Llf/9Gd5wRvenb972uFJkltttyqP+fV757gPnjlypbC0GGBfBK21tUnWJsmqW+21PL/iLGlvWfvqXPzFr+a1r1s7dikAXXrG4QfnGYcfnCT5zLr/zHEfPDN/97TD84Mrfpzb7bZzWmv5+LlfyF33NnMHTLkZqaodMrvpYZLslWTnqjp08vjfWmvXTPPzYUgPPPA++YPfPzQXfn5dzv3MR5IkL3rRy/KhD39s5MoA+veCN7w7V/zk6rTW8kt3vmNedOQhY5cES8py3S+jWpteAFFV+yb5+iaevktr7Rubeq9kBGDLXfXpN4xdAsCSsv2vPbbmf9X4jtj3dxftZ+PjvvHeRfuaTHvTw28kWRL/AwMAQK9mphggjMlqWgAAwCi6GmAHAAB+3vLMRSQjAADASCQjAADQuZllmo1IRgAAgFFIRgAAoHPLdQd2yQgAADAKyQgAAHRuue7ALhkBAABGIRkBAIDOWU0LAABgQJoRAABgFC7TAgCAzlnaFwAAYECSEQAA6JylfQEAAAYkGQEAgM61ZmYEAABgMJIRAADonE0PAQAABiQZAQCAzllNCwAAYECSEQAA6Jwd2AEAAAYkGQEAgM5ZTQsAAGBAkhEAAOicHdgBAAAGpBkBAABG4TItAADonE0PAQAABiQZAQCAztn0EAAAYECSEQAA6JxNDwEAgBWvqt5WVZdW1UVzjq2uqtOq6iuTP3dbyLk0IwAA0LnW2qLdFuDtSR610bHnJzm9tXa3JKdPHs9LMwIAACxYa+3MJJdvdPgxSY6b3D8uyWMXci4zIwAA0LklMDNy+9ba9yb3L0ly+4W8STICAADcoKrWVNW5c25rtuT9bfZarwV1T5IRAADo3GLuM9JaW5tk7Ra+7ftVtWdr7XtVtWeSSxfyJskIAABwS30gyRGT+0ckOXkhb5KMAABA52YWtsrVoqiqE5I8JMnuVfWdJEcleVmSE6vqyCTfTPL4hZxLMwIAACxYa+0Jm3jqYVt6Ls0IAAB0rp9cZFhmRgAAgFFoRgAAgFG4TAsAADq3BDY93CqSEQAAYBSSEQAA6JxkBAAAYECSEQAA6FzraNPDIUlGAACAUUhGAACgc2ZGAAAABiQZAQCAzjXJCAAAwHAkIwAA0DmraQEAAAxIMgIAAJ2zmhYAAMCAJCMAANA5MyMAAAAD0owAAACjcJkWAAB0zgA7AADAgCQjAADQuSYZAQAAGI5kBAAAOjdjaV8AAIDhSEYAAKBzZkYAAAAGJBkBAIDOmRkBAAAYkGQEAAA6Z2YEAABgQJIRAADonJkRAACAAUlGAACgc2ZGAAAABqQZAQAARuEyLQAA6JwBdgAAgAFJRgAAoHMG2AEAAAYkGQEAgM61NjN2CVMhGQEAAEYhGQEAgM7NmBkBAAAYjmQEAAA61+wzAgAAMBzJCAAAdM7MCAAAwIAkIwAA0DkzIwAAAAOSjAAAQOdmJCMAAADD0YwAAACjcJkWAAB0rlnaFwAAYDiSEQAA6JylfQEAAAYkGQEAgM7NmBkBAAAYjmQEAAA6Z2YEAABgQJIRAADo3IxkBAAAYDiSEQAA6JyZEQAAgAFJRgAAoHP2GQEAABiQZAQAADpnZgQAAGBAkhEAAOicfUYAAAAGpBkBAABG4TItAADoXLO0LwAAwHAkIwAA0DkD7AAAAAOSjAAAQOdseggAADAgyQgAAHTOaloAAAADkowAAEDnzIwAAAAMSDICAACdk4wAAAAMSDICAACdW565iGQEAAAYSS3X689gWqpqTWtt7dh1ACwlvncCN0cyAltuzdgFACxBvncCP0czAgAAjEIzAgAAjEIzAlvONc8AW873TuDnGGAHAABGIRkBAABGoRkBAABGoRkBAABGoRlhxauqGrsGAICVSDPCilVVG/77v9WohQAsUXO+jwJsFd9EWJGqaqckb66qjyV5X1U9o6p2HLsugN5V1Q5V9Zgkaa3NaEiAW8I3EFacqtohydlJ7pbkq0kuS/LqJCdX1cPHrA2gZ5Pvn59McnxV/UmiIQFumVVjFwAjeHyS7ZIc2Vr7zySpqtckeX+Sl1XV6tbae0asD6A7VbUqs7+42SfJuiTPrKptW2tv2tCQtNZmxq0SWGr8JoOVaM8kmdOIbNdaOz/JgybPP7eqHjVWcQCd2i/JQ5N8IMmfJflSkqdX1VMSCQmwdXzTYCW6MMneVfWgJGmtXVdVq1pr30pySJLdkjy/qm47ZpEAnfl2klcleU5r7Zwk/yfJl/PzDcm2I9YILDGaEVaiTyc5P8mfVNWdk6S1dv2chuS3k9w/yZoRawToSmvtp0ne2lq7fE6ifFR+viFZb8l0YKE0I6w4rbXLkzwzs03HkVW1x+T49VV1q9baRUn+MclvVdUu/lEFmNVaa5M/r5v8+bnctCHZ8EucO1fVYeNUCSwlBthZkVpr51TVoUlOTdKq6tjW2rdba9dOXnJ1kp2SXLPhH18Afl5r7XNV9eLMNiXPrKrdk/xakkOq6ozW2vdHLRDommSEFau19tEkj0zyrCRHVdUDkmTyD+k+mb0+ervxKgTo32QVrQsy24x8M8lLkzwkyb01IsB8JCOsaK21j1bVI5K8PsmHquork6d+MclDWmvXjFcdQP/mLOd7SZJfSPKjJA9qra0brypgqShXoEBSVbdPclCS/5nZ3+y9v7X25XGrAlgaJpshHpvk8CQHtNYuHLkkYInQjAAAt9gkZf5ea+3zY9cCLB2aEQAAYBQG2AEAgFFoRgAAgFFoRgAAgFFoRgAAgFFoRgAAgFFoRgC2UlWtr6oLquqiqjppstfC1p7r7VV16OT+sVW1/2Ze+5CqOnArPuMbVbX7Qo9v9JqrtvCzXlxVz9nSGgFYWTQjAFvvp621A1pr90hybZKnzH2yqlZtzUlba388z+7VD0myxc0IAPRGMwIwjE8kuesktfhEVX0gybqq2raqXllVn6mqC6vqyUlSs46pqi9V1UeT7LHhRFV1RlXde3L/UVV1XlV9rqpOr6p9M9v0PGuSyjyoqm5XVe+dfMZnquqBk/fetqo+UlVfqKpjk9R8f4mqen9VfXbynjUbPfeayfHTq+p2k2O/WFUfnrznE1V190G+mgCsCFv1WzsAbjRJQA5O8uHJoXsluUdr7euTH+h/1Fq7T1X9QpJPVtVHkvxqkl9Ksn+S2ydZl+RtG533dknekuTBk3Otbq1dXlVvSnJVa+1Vk9e9K8lrWmtnVdWdkpya5L8nOSrJWa21l1TVbyY5cgF/nT+afMatk3ymqt7bWrssyY5Jzm2tPauq/mZy7j9LsjbJU1prX6mq+yV5Y5KDtuLLCMAKpBkB2Hq3rqoLJvc/keStmb186pzW2tcnxx+R5Fc2zIMk2SXJ3ZI8OMkJrbX1Sb5bVR+7mfPfP8mZG87VWrt8E3X8RpL9q24IPnauqttMPuN3Ju/9YFVdsYC/09Or6pDJ/X0mtV6WZCbJeybH35nkfZPPODDJSXM++xcW8BkAkEQzAnBL/LS1dsDcA5Mfyq+eeyjJn7fWTt3odY8esI5tkty/tfb/bqaWBauqh2S2sXlAa+2aqjojyfabeHmbfO6VG38NAGChzIwATNepSZ5aVdslSVX9t6raMcmZSQ6bzJTsmeShN/Pe/0jy4Kq6y+S9qyfHf5Jkpzmv+0iSP9/woKoOmNw9M8kTJ8cOTrLbPLXukuSKSSNy98wmMxtsk2RDuvPEzF7+9eMkX6+qx00+o6rqnvN8BgDcQDMCMF3HZnYe5LyquijJmzObSv9Lkq9MnntHkk9v/MbW2g+SrMnsJVGfy42XSZ2S5JANA+xJnp7k3pMB+XW5cVWvozPbzHwhs5drfWueWj+cZFVVXZzkZZlthja4Osl9J3+Hg5K8ZHL895IcOanvC0kes4CvCQAkSaq1NnYNAADACiQZAQAARqEZAQAARqEZAQAARqEZAQAARqEZAQAARqEZAQAARqEZAQAARqEZAQAARvH/AdhxLA9L+452AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8305, 0.9574])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.class_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Fine-tuned balanced_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = f'{save_path}_balanced'\n",
    "log_dir = f'{log_path}_balanced'\n",
    "\n",
    "dict_model = dict(\n",
    "    shared_out_dim=[125,75,200],\n",
    "    state_layers=[[20], [30]],\n",
    "    action_layers=[[20], [30]],\n",
    "    out_features=[1],\n",
    "    lstm_model=[False],\n",
    "    bert_name=[\"bert-base-multilingual-cased\"],\n",
    "    # training parameters\n",
    ")\n",
    "\n",
    "list_model = [dict(zip(dict_model.keys(), k)) for k in itertools.product(*dict_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "shared_out_dim=125/state_layers=[20]/action_layers=[20]/out_features=1/lstm_model=False/bert_name=bert-base-multilingual-cased/train_lr=0.001/train_optimizer_name=adamw/train_batch_size=8/train_scheduler_mode=max_val_acc/train_balanced_actions=True/train_augment_negative=True/train_scheduler_patience=450 -> 0:   0%|          | 0/4500 [00:00<?, ?it/s]\n",
      "  0%|          | 0/12 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\notebooks\\models_training.ipynb Cell 32'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=2'>3</a>\u001b[0m set_seed(seed)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=3'>4</a>\u001b[0m d \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=5'>6</a>\u001b[0m train(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=6'>7</a>\u001b[0m     model\u001b[39m=\u001b[39;49mStateActionModel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=7'>8</a>\u001b[0m     dict_model\u001b[39m=\u001b[39;49md,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=8'>9</a>\u001b[0m     log_dir\u001b[39m=\u001b[39;49mlog_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=9'>10</a>\u001b[0m     graph\u001b[39m=\u001b[39;49mgraph,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=10'>11</a>\u001b[0m     save_path\u001b[39m=\u001b[39;49msave_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=11'>12</a>\u001b[0m     lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=12'>13</a>\u001b[0m     optimizer_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39madamw\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=13'>14</a>\u001b[0m     n_epochs\u001b[39m=\u001b[39;49m\u001b[39m4500\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=14'>15</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=15'>16</a>\u001b[0m     num_workers\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=16'>17</a>\u001b[0m     scheduler_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_val_acc\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=17'>18</a>\u001b[0m     debug_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=18'>19</a>\u001b[0m     steps_save\u001b[39m=\u001b[39;49m\u001b[39m450\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=19'>20</a>\u001b[0m     use_cpu\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=20'>21</a>\u001b[0m     freeze_bert\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=21'>22</a>\u001b[0m     balanced_actions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=22'>23</a>\u001b[0m     augment_negative\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=23'>24</a>\u001b[0m     scheduler_patience\u001b[39m=\u001b[39;49m\u001b[39m450\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vibal/PycharmProjects/text-games/notebooks/models_training.ipynb#ch0000031?line=24'>25</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\notebooks\\..\\models\\train.py:155\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dict_model, graph, log_dir, save_path, lr, optimizer_name, n_epochs, batch_size, num_workers, scheduler_mode, debug_mode, device, steps_save, use_cpu, freeze_bert, balanced_actions, augment_negative, scheduler_patience)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/train.py?line=151'>152</a>\u001b[0m model\u001b[39m.\u001b[39mfreeze_bert(freeze_bert)\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/train.py?line=152'>153</a>\u001b[0m \u001b[39mfor\u001b[39;00m state, action, reward \u001b[39min\u001b[39;00m loader_train:\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/train.py?line=153'>154</a>\u001b[0m     \u001b[39m# Compute loss and update parameters\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/train.py?line=154'>155</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(state, action)[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/train.py?line=155'>156</a>\u001b[0m     loss_val \u001b[39m=\u001b[39m loss(pred, reward)\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/train.py?line=157'>158</a>\u001b[0m     \u001b[39m# Do back propagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\notebooks\\..\\models\\models.py:275\u001b[0m, in \u001b[0;36mStateActionModel.forward\u001b[1;34m(self, state, action)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=267'>268</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, state: Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor], action: Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=268'>269</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=269'>270</a>\u001b[0m \u001b[39m    Method which runs the given input through the classifier\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=270'>271</a>\u001b[0m \u001b[39m    :param action: dict of torch.Tensor(B,input_size), output of the tokenizer\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=271'>272</a>\u001b[0m \u001b[39m    :param state: dict of torch.Tensor(B,input_size), output of the tokenizer\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=272'>273</a>\u001b[0m \u001b[39m    :return: torch.Tensor(B, out_features)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=273'>274</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=274'>275</a>\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshared(state))\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=275'>276</a>\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared(action))\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=276'>277</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(torch\u001b[39m.\u001b[39mconcat((state, action), \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\notebooks\\..\\models\\models.py:128\u001b[0m, in \u001b[0;36mStateActionModel.BertSharedBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=121'>122</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=122'>123</a>\u001b[0m \u001b[39mMethod which runs the given input through the block\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=123'>124</a>\u001b[0m \u001b[39m:param x: dict of torch.Tensor(B,sequence_length), output of the tokenizer\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=124'>125</a>\u001b[0m \u001b[39m:return: torch.Tensor(B,out_features)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=125'>126</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=126'>127</a>\u001b[0m \u001b[39m# z = self.bert(**x)\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=127'>128</a>\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(input_ids\u001b[39m=\u001b[39;49mx[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m], token_type_ids\u001b[39m=\u001b[39;49mx[\u001b[39m'\u001b[39;49m\u001b[39mtoken_type_ids\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=128'>129</a>\u001b[0m attention_mask\u001b[39m=\u001b[39;49mx[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/notebooks/../models/models.py?line=129'>130</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet(z[\u001b[39m'\u001b[39m\u001b[39mpooler_output\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=986'>987</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=988'>989</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=989'>990</a>\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=990'>991</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=993'>994</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=994'>995</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=995'>996</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=996'>997</a>\u001b[0m     embedding_output,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=997'>998</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=998'>999</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=999'>1000</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1000'>1001</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1001'>1002</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1002'>1003</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1003'>1004</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1004'>1005</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1005'>1006</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1006'>1007</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1007'>1008</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=1008'>1009</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=575'>576</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=576'>577</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=577'>578</a>\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=581'>582</a>\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=582'>583</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=583'>584</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=584'>585</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=585'>586</a>\u001b[0m         hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=586'>587</a>\u001b[0m         attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=587'>588</a>\u001b[0m         layer_head_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=588'>589</a>\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=589'>590</a>\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=590'>591</a>\u001b[0m         past_key_value,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=591'>592</a>\u001b[0m         output_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=592'>593</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=594'>595</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=595'>596</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=459'>460</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=460'>461</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=461'>462</a>\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=468'>469</a>\u001b[0m ):\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=469'>470</a>\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=470'>471</a>\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=471'>472</a>\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=472'>473</a>\u001b[0m         hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=473'>474</a>\u001b[0m         attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=474'>475</a>\u001b[0m         head_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=475'>476</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=476'>477</a>\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=477'>478</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=478'>479</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=480'>481</a>\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=391'>392</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=392'>393</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=393'>394</a>\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=399'>400</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=400'>401</a>\u001b[0m ):\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=401'>402</a>\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=402'>403</a>\u001b[0m         hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=403'>404</a>\u001b[0m         attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=404'>405</a>\u001b[0m         head_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=405'>406</a>\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=406'>407</a>\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=407'>408</a>\u001b[0m         past_key_value,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=408'>409</a>\u001b[0m         output_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=409'>410</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=410'>411</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=411'>412</a>\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:268\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=258'>259</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=259'>260</a>\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=265'>266</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=266'>267</a>\u001b[0m ):\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=267'>268</a>\u001b[0m     mixed_query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(hidden_states)\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=269'>270</a>\u001b[0m     \u001b[39m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=270'>271</a>\u001b[0m     \u001b[39m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=271'>272</a>\u001b[0m     \u001b[39m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/transformers/models/bert/modeling_bert.py?line=272'>273</a>\u001b[0m     is_cross_attention \u001b[39m=\u001b[39m encoder_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\vibal\\PycharmProjects\\text-games\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/functional.py?line=1845'>1846</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[0;32m   <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/functional.py?line=1846'>1847</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[1;32m-> <a href='file:///c%3A/Users/vibal/PycharmProjects/text-games/venv/lib/site-packages/torch/nn/functional.py?line=1847'>1848</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        set_seed(seed)\n",
    "        d = d.copy()\n",
    "\n",
    "        train(\n",
    "            model=StateActionModel(**d),\n",
    "            dict_model=d,\n",
    "            log_dir=log_dir,\n",
    "            graph=graph,\n",
    "            save_path=save_model,\n",
    "            lr=1e-3,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=4500,\n",
    "            batch_size=8,\n",
    "            num_workers=0,\n",
    "            scheduler_mode='max_val_acc',\n",
    "            debug_mode=False,\n",
    "            steps_save=450,\n",
    "            use_cpu=False,\n",
    "            freeze_bert=True,\n",
    "            balanced_actions=True,\n",
    "            augment_negative=True,\n",
    "            scheduler_patience=450,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = test(\n",
    "    graph=graph,\n",
    "    save_path=save_model,\n",
    "    n_runs=1,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    debug_mode=False,\n",
    "    use_cpu=False,\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "toast.show_toast(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = all[sort_idx[0]]['test_cm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37be9487e307834247f9cc00a1ec46ceeb3f522b7edf17e3b2d74c6ce713e314"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
